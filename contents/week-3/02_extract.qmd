---
title: "Extract"
engine: knitr
---

```{r}
#| eval: true
#| include: false
#| class-output: outputcode
library(tidyverse)

THEONE_TOKEN <- Sys.getenv("THEONE_TOKEN")
```

<br>
As we have seen, data extraction is the fundamental process of acquiring data from diverse sources. In this section, we focus on two specific methods for data retrieval: utilising APIs and employing web scraping techniques.

## Using APIs

An API (Application Programming Interface) is a set of rules and protocols that enables different software applications to communicate with each other. It serves as an intermediary that allows one software system to request and exchange data or functionality from another, whether locally or over a network, like internet. APIs are a fundamental tool in modern software development, as they facilitate the integration of different services and systems, enabling the seamless exchange of data and functionality. They are commonly used for accessing web services, databases, and external platforms, making them a pivotal component in building interconnected and data-driven applications.

::: {.callout-note appearance="simple"}

## Example

We will use [The One API](https://the-one-api.dev) to fetch a Lord of the Rings database. We will need the `httr2` package, so we load it.

```{r}
#| eval: true
#| class-output: outputcode
# Load the library
library(httr2)
```

The first step is to create a request to connect to the API. Most APIs require a token to be connected. You can get your token by creating an account on [The One API](https://the-one-api.dev) website. For the following, we assume that the token is created and set into the variable `THEONE_TOKEN`.

```{r}
#| class-output: outputcode
#| eval: true
req <- request("https://the-one-api.dev/v2") |>  # Create the request
    req_auth_bearer_token(THEONE_TOKEN)  # API token
```

Note that, here, the request is only created and nothing is actually sent to the API. The API documention gives the available routes. Imagine we want to retrieve all the characters in The Lord of the Rings books.

```{r}
#| class-output: outputcode
#| eval: true
#| cache: true
resp <- req |>  
    req_url_path_append("character") |>  # Create the route
    req_perform()  # The request is only sent here
```

We can check that everything went fine by looking at the status code which should be equal to $200$.

```{r}
#| class-output: outputcode
#| eval: true
resp$status_code
```

The next step is to read the results from the request (and convert them into a tibble).

```{r}
#| class-output: outputcode
#| eval: true
characters <- resp |> 
    resp_body_json() |>  # Read the results
    pluck("docs") |>  # Extract the docs field (specific to this API)
    map_dfr(function(x) {x = flatten(x)}) |>  # Convert to tibble
    as_tibble()

characters |> filter(name == 'Gollum')
```

Finally, we may consider another route. For example, we would like to find a specific quote from Gollum: **"My precious."**

```{r}
#| class-output: outputcode
#| eval: true
id_gollum <- characters |> filter(name == 'Gollum') |> pull(`_id`)
quotes <- req |>
    req_url_path_append(paste0("character/", id_gollum, "/quote")) |> 
    req_perform() |> 
    resp_body_json() |> 
    pluck("docs")

quotes[[10]]$dialog
```

:::

## Web scrapping

Web scraping is a data extraction technique that involves automatically retrieving information from websites. It entails the automated parsing of HTML or other markup languages used to structure web pages, allowing the extraction of specific data elements. Web scraping is employed for a variety of purposes, such as collecting data for research, monitoring online content, aggregating information for analysis, and more. It is however important to note that web scraping should be performed ethically and in accordance with the terms of service of the website to respect the rights and policies of web content providers.

::: {.callout-note appearance="simple"}
The legality of web scraping is open to debate and can vary considerably from one jurisdiction to another. In a general context, web scraping may contravene the terms of service of certain websites. The extent to which these terms can be legally enforced however remains an area of uncertainty and contention.
:::

::: {.callout-note appearance="simple"}
You can determine whether it is permissible to crawl a website by consulting the `robots.txt` file located at the website's root. The address should look similar to `http://example.com/robots.txt`.
:::

::: {.callout-note appearance="simple"}

## Example

We will use the Wikipedia page [List of Billboard Hot 100 number ones of 2022](https://en.wikipedia.org/wiki/List_of_Billboard_Hot_100_number_ones_of_2022) to scrap the list of songs that placed number one in the US during 2022. We will need the `rvest` package, so we load it.

```{r}
#| eval: true
#| warning: false
#| class-output: outputcode
# Load the library
library(rvest)
```


The concept of web scraping is rather straightforward. We use the `read_html()` function to retrieve HTML pages and subsequently choose the desired elements with the `html_elements()` function.

```{r}
#| eval: true
#| class-output: outputcode
WIKI_URL <- "https://en.wikipedia.org/wiki/"
URL <- "List_of_Billboard_Hot_100_number_ones_of_2022"
pages <- read_html(paste0(WIKI_URL, URL))

tables <- pages |>
    html_elements("table") |>  # Get HTML elements with table attributes
    html_table()  # Convert the HTML tables into tibbles

```

Examining the Wikipedia page reveals that the table of interest is the second one. Consequently, we select this table. Notably, the table still requires significant refinement to prepare the data for analysis. This refinement constitutes the objective of the second ETL step: Transform.

```{r}
#| eval: true
#| class-output: outputcode
# Load the library
head(tables[[2]])
```

:::


## Additional resources

* [An article](https://www.infoworld.com/article/3269878/what-is-an-api-application-programming-interfaces-explained.html) on APIs.

* The One API [webiste](https://the-one-api.dev).

* [An article](https://web.archive.org/web/20120624103316/http://www.lkshields.ie/htmdocs/publications/newsletters/update26/update26_03.htm) on the legality of web scrapping with the case *Ryanair Limited v Billigfluege.de GmbH* and the [court decision](http://www.bailii.org/ie/cases/IEHC/2010/H47.html).

* [An article](https://www.bbc.com/news/technology-23988890) on the ethics of web scrapping from the BBC.

<br><br>

::: {style="font-size: 0.875em;"}
[Back](/weeks/week-3.qmd) ‚èé
:::