---
title: "Large Language Models - Questionnaire"
engine: knitr
---

<br>

```{r}
#| echo: false
library(webexercises)
```

<br>

```{r}
#| class: webex-box
#| echo: false
#| results: asis
question <- "In the context of Large Language Models, what does 'NLP' stand for?"
question_choices <- c(
    answer = "Natural Language Processing",
    "Neural Learning Platform",
    "Networked Language Processing",
    "None of the above"
)
cat(question, longmcq(sample(question_choices)))
```

<br>

```{r}
#| class: webex-box
#| echo: false
#| results: asis
question <- "What is the primary application of LLM like GPT-3?"
question_choices <- c(
    answer = "Natural language understanding and generation",
    "Image processing",
    "Speech recognition",
    "Video game development"
)
cat(question, longmcq(sample(question_choices)))
```

<br>

```{r}
#| class: webex-box
#| echo: false
#| results: asis
question <- "Who develop the GPT models?"
question_choices <- c(
    answer = "OpenAI",
    "Google",
    "Meta",
    "Amazon"
)
cat(question, longmcq(sample(question_choices)))
```

<br>

```{r}
#| class: webex-box
#| echo: false
#| results: asis
question <- "What is the key advantage of LLM in natural language processing tasks?"
question_choices <- c(
    answer = "Ability to generate coherent and context-aware text",
    "High energy efficiency",
    "Real-time language translation",
    "Fast execution speed"
)
cat(question, longmcq(sample(question_choices)))
```

<br>

```{r}
#| class: webex-box
#| echo: false
#| results: asis
question <- "What architecture is commonly used in LLM?"
question_choices <- c(
    answer = "Transformer-based neural network",
    "RNN (Recurrent Neural Network)",
    "CNN (Convolutional Neural Network)",
    "Decision tree"
)
cat(question, longmcq(sample(question_choices)))
```

<br><br>

::: {style="font-size: 0.875em;"}
Back to [week 11](/weeks/week-11.qmd) ‚èé
:::