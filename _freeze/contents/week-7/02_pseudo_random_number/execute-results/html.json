{
  "hash": "90f677d25ef11c4e867e861743c6332c",
  "result": {
    "markdown": "---\ntitle: \"Pseudo-random number\"\nengine: knitr\n---\n\n\nPseudo-random numbers are not random in the way you might expect!\n\n\n::: {.callout-note appearance=\"simple\"}\n\n## D. H. Lehmer [@lehmer1951]\n\nA random sequence is a vague notion in which each term is unpredictable to the uninitiated, and whose digits pass a certain number of tests traditional with statisticians...\n:::\n\nA pseudo-random sequence have the appearance of random numbers, but are in fact completely deterministic. Pseudo-random number generator are algorithms that use mathematical formulae to produce sequcnes of numbers that appear random.\n\nR uses a pseudo-random generator named the Mersenne-Twister generator. Its cycle length is $2^{19937} - 1$.\n\n\nLet's see what happen when we generate some realizations from a uniform distributions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(42)\nrunif(4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.outputcode}\n[1] 0.9148060 0.9370754 0.2861395 0.8304476\n```\n:::\n\n```{.r .cell-code}\nrunif(4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.outputcode}\n[1] 0.6417455 0.5190959 0.7365883 0.1346666\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(42)\nrunif(4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.outputcode}\n[1] 0.9148060 0.9370754 0.2861395 0.8304476\n```\n:::\n:::\n\n\n::: {.callout-important icon=false}\n## Replication\n\nTo perform an exact replication of your program, you have to specify the seed using the `seed()` function!\n:::\n\n\n## The inverse-transform method\n\nLet $P$ be a probability distribution defined on $\\mathbb{R}$ or $\\mathbb{R}^d$. We aim to generate an _independent_ and _identically distributed_ sample $X_1, \\dots, X_n$ with the same distribution $P$. All random variables can be generated from the uniform distribution $\\mathcal{U}(0, 1)$. So, it suffices to generate an iid sample $U_1, \\dots, U_n$ from $\\mathcal{U}(0, 1)$.\n\nAssume we know the cumulative distribution function $F$ of $P$. We note $F^{-1}$ the inverse function of $F$ when $F: \\mathbb{R} \\rightarrow [0, 1]$ is one-to-one, defined as\n$$F^{-1}(u) = \\inf \\{x \\in \\mathbb{R}, F(x) \\geq u\\}.$$\n\nThen, if $U \\sim \\mathcal{U}(0, 1)$, $F^{-1}(U)$ has the same distribution as $X$. And its reciprocal, if the cumulative distribution function $F$ is continue, then $F(X) \\sim \\mathcal{U}(0, 1)$.\n\n::: {.callout-note icon=false}\n## Algorithm: the inverse-transform method\n\nVariables:\n\n* $n$: length of the sample\n* $F$: cumulative distribution function of the output sample\n\nAlgorithm:\n\n<div class=\"pseudocode\">\n\n**for** $i$ **from** $1$ **to** $n$ **do**\n\n* generate $u_i \\sim \\mathcal{U}(0, 1)$\n* compute $x_i = F^{-1}(u_i)$\n\n**endfor**\n</div>\n\nOutput:\n\n* Sample $(x_1, \\dots, x_n)$ with cumulative distribution function $F$.\n:::\n\n### Example: **Simulation of a sample from** $\\mathcal{E}(\\theta)$\n\nWe aim to generate a sample $x_1, \\dots, x_n$ i.i.d. from $\\mathcal{E}(\\theta)$. The cumulative distribution function of $\\mathcal{E}(\\theta)$ is given by\n$$F(x, \\theta) = 1 - \\exp(-\\theta x), \\quad x \\geq 0.$$\nSolving the equation $F(x, \\theta) = u$, we find the inverse of the cumulative distribution function\n$$F^{-1}(u, \\theta) = -\\frac{1}{\\theta}\\log(1 - u).$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(42)               # seed setting\ntheta <- 4; n <- 10000     # parameters setting\nu <- runif(n)              # uniform sample\nx <- -log(1 - u) / theta   # inverse transform method\n\nks.test(x, \"pexp\", theta)  # Kolmogorov Smirnov test\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.outputcode}\n\n\tAsymptotic one-sample Kolmogorov-Smirnov test\n\ndata:  x\nD = 0.010639, p-value = 0.2077\nalternative hypothesis: two-sided\n```\n:::\n:::\n\n\n\n### Example: **Simulation of a sample from** $\\mathcal{B}(\\theta)$\n\nWe aim to generate a sample $x_1, \\dots, x_n$ i.i.d from $\\mathcal{B}(\\theta)$ (where $\\theta \\in [0,1]$). The cumulative distribution function of $\\mathcal{B}(\\theta)$ is given by\n$$F(x) = \\left\\{\n\\begin{array}{r c l}\n    1 &\\text{if}& x \\geq 1,\\\\\n    1 - \\theta &\\text{if}& x \\in [0,1[,\\\\\n    0 &if& x < 0.\n\\end{array}\n\\right.\n$$ \nSolving the equation $F(x, \\theta) = u$, we find the inverse of the cumulative distribution function\n$$F^{-1}(u) = \\left\\{\n\\begin{array}{r c l}\n    1 &\\text{if}& u \\in [1-\\theta,1], \\\\\n    0 &\\text{if}& u \\in [0,1-\\theta[.\n\\end{array}\n\\right.\n$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(10)              # seed setting\ntheta <- 0.4; n <- 10000  # parameters setting\nu <- runif(n)             # uniform sampling\nx <- (u > (1 - theta))    # inverse transform method\n\nchisq.test(table(x), p = c(1 - theta, theta))  # chisq test\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.outputcode}\n\n\tChi-squared test for given probabilities\n\ndata:  table(x)\nX-squared = 0.375, df = 1, p-value = 0.5403\n```\n:::\n:::\n\n\n### References\n\n::: {#refs}\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}