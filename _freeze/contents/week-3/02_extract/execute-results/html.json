{
  "hash": "1bbf6e6bc6d40cfaf9020893ddea771e",
  "result": {
    "markdown": "---\ntitle: \"Extract\"\nengine: knitr\n---\n\n\n\n\n<br>\nAs we have explored, data extraction is the fundamental process of acquiring data from diverse sources. In this section, we focus on two specific methods for data retrieval: utilising APIs and employing web scraping techniques.\n\n## Using APIs\n\nAn API (Application Programming Interface) is a set of rules and protocols that enables different software applications to communicate with each other. It serves as an intermediary that allows one software system to request and exchange data or functionality from another, whether locally or over a network, like internet. APIs are a fundamental tool in modern software development, as they facilitate the integration of different services and systems, enabling the seamless exchange of data and functionality. They are commonly used for accessing web services, databases, and external platforms, making them a pivotal component in building interconnected and data-driven applications.\n\n::: {.callout-note appearance=\"simple\"}\n\n## Example\n\nWe will use [The One API](https://the-one-api.dev) to fetch a Lord of the Rings database. We will need the `httr2` package, so we load it.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load the library\nlibrary(httr2)\n```\n:::\n\n\nThe first step is to create a request to connect to the API. Most APIs require a token to be connected. You can get your token by creating an account on [The One API](https://the-one-api.dev) website. For the following, we assume that the token is created and set into the variable `THEONE_TOKEN`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nreq <- request(\"https://the-one-api.dev/v2\") |>  # Create the request\n    req_auth_bearer_token(THEONE_TOKEN)  # API token\n```\n:::\n\n\nNote that, here, the request is only created and nothing is actually sent to the API. The API documention gives the available routes. Imagine we want to retrieve all the characters in The Lord of the Rings books.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresp <- req |>  \n    req_url_path_append(\"character\") |>  # Create the route\n    req_perform()  # The request is only sent here\n```\n:::\n\n\nWe can check that everything went fine by looking at the status code which should be equal to $200$.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresp$status_code\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.outputcode}\n[1] 200\n```\n:::\n:::\n\n\nThe next step is to read the results from the request (and convert them into a tibble).\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncharacters <- resp |> \n    resp_body_json() |>  # Read the results\n    pluck(\"docs\") |>  # Extract the docs field (specific to this API)\n    map_dfr(function(x) {x = flatten(x)}) |>  # Convert to tibble\n    as_tibble()\n\ncharacters |> filter(name == 'Gollum')\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.outputcode}\n# A tibble: 1 × 11\n  `_id`         height race  gender birth spouse death realm hair  name  wikiUrl\n  <chr>         <chr>  <chr> <chr>  <chr> <chr>  <chr> <chr> <chr> <chr> <chr>  \n1 5cd99d4bde30… \"\"     Hobb… Male   TA 2… \"\"     Marc… \"\"    \"\"    Goll… http:/…\n```\n:::\n:::\n\n\nFinally, we may consider another route. For example, we would like to find a specific quote from Gollum: **\"My precious.\"**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nid_gollum <- characters |> filter(name == 'Gollum') |> pull(`_id`)\nquotes <- req |>\n    req_url_path_append(paste0(\"character/\", id_gollum, \"/quote\")) |> \n    req_perform() |> \n    resp_body_json() |> \n    pluck(\"docs\")\n\nquotes[[10]]$dialog\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.outputcode}\n[1] \"My precious.\"\n```\n:::\n:::\n\n\n:::\n\n## Web scrapping\n\nWeb scraping is a data extraction technique that involves automatically retrieving information from websites. It entails the automated parsing of HTML or other markup languages used to structure web pages, allowing the extraction of specific data elements. Web scraping is employed for a variety of purposes, such as collecting data for research, monitoring online content, aggregating information for analysis, and more. It is however important to note that web scraping should be performed ethically and in accordance with the terms of service of the website to respect the rights and policies of web content providers.\n\n::: {.callout-note appearance=\"simple\"}\nThe legality of web scraping is open to debate and can vary considerably from one jurisdiction to another. In a general context, web scraping may contravene the terms of service of certain websites. The extent to which these terms can be legally enforced however remains an area of uncertainty and contention.\n:::\n\n::: {.callout-note appearance=\"simple\"}\nYou can determine whether it is permissible to crawl a website by consulting the `robots.txt` file located at the website's root. The address should look similar to `http://example.com/robots.txt`.\n:::\n\n::: {.callout-note appearance=\"simple\"}\n\n## Example\n\nWe use the Wikipedia page [List of Billboard Hot 100 number ones of 2022](https://en.wikipedia.org/wiki/List_of_Billboard_Hot_100_number_ones_of_2022) to scrap the list of songs that placed number one in the US during 2022. We will need the `rvest` package, so we load it.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load the library\nlibrary(rvest)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load the library\nURL <- \"https://en.wikipedia.org/wiki/List_of_Billboard_Hot_100_number_ones_of_2022\"\nsongs <- read_html(URL)\n\ntables <- songs |> html_elements(\"table\") |> html_table()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load the library\nhead(tables[[2]])\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.outputcode}\n# A tibble: 6 × 5\n  No.   `Issue date` Song                                  `Artist(s)`     Ref. \n  <chr> <chr>        <chr>                                 <chr>           <chr>\n1 re    January 1    \"\\\"All I Want for Christmas Is You\\\"\" Mariah Carey    [10]…\n2 re    January 8    \"\\\"All I Want for Christmas Is You\\\"\" Mariah Carey    [12]…\n3 re    January 15   \"\\\"Easy on Me\\\"\"                      Adele           [14]…\n4 re    January 22   \"\\\"Easy on Me\\\"\"                      Adele           [16]…\n5 re    January 29   \"\\\"Easy on Me\\\"\"                      Adele           [18]…\n6 1133  February 5   \"\\\"We Don't Talk About Bruno\\\"\"       Carolina Gaitá… [20]…\n```\n:::\n:::\n\n\n:::\n\n\n## Additional resources\n\n* [An article](https://www.infoworld.com/article/3269878/what-is-an-api-application-programming-interfaces-explained.html) on APIs.\n\n* The One API [webiste](https://the-one-api.dev).\n\n* [An article](https://web.archive.org/web/20120624103316/http://www.lkshields.ie/htmdocs/publications/newsletters/update26/update26_03.htm) on the legality of web scrapping with the case *Ryanair Limited v Billigfluege.de GmbH* and the [court decision](http://www.bailii.org/ie/cases/IEHC/2010/H47.html).\n\n* [An article](https://www.bbc.com/news/technology-23988890) on the ethics of web scrapping from the BBC.",
    "supporting": [
      "02_extract_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}