{
  "hash": "8c19902a728e91f870ecfb0a3b123b5e",
  "result": {
    "markdown": "---\ntitle: \"ETL - Tutorial\"\nengine: knitr\n---\n\n\n<br>\nToday's tutorial has two purposes. Firstly, it aims to acquaint you with an API for data retrieval, enhance your expertise in using the `tidyverse` for data cleaning, investigate diverse output formatting techniques, and finalise the session with a simple scheduling procedure to automate API requests. Secondly, it focuses on familiarising you with web scraping.\n\n## Part 1 - The Movies Database\n\nFor the API, we use the [MoviesDatabase](https://rapidapi.com/SAdrian/api/moviesdatabase/details) from [RapidAPI](https://rapidapi.com/hub). You will need to create an account on RapidAPI to access the APIs. If you prefer using another API, feel free to change.\n\n1. Connect to the database.\n\n2. Go on [IMDB](https://www.imdb.com), find a tv serie you like, and get it's id (it is in the URL).\n\n3. Make a request to obtain all the identifiers for the episodes in the series. Transform it to a tibble.\n\n4. For each episode, make a request to obtain some information about it (name, duration, storyline, ...)\n\n5. For each episode, make a request to obtain their ratings.\n\n6. Clean the collected data to make a proper tibble.\n\n7. Plot the evolution of the rankings through the season.\n\n8. Export the data set in csv form.\n\n9. Automate the script.\n\n\n## Part 2 - Wikipedia scrapping\n\nRegarding web scraping, our focus will be on extracting data from Wikipedia. Specifically, we will assemble a dataset that compiles information from all the counties in Ireland.\n\n10. Go on the Wikipedia page of [Ireland counties](https://en.wikipedia.org/wiki/Counties_of_Ireland). Create a scrapper to get a list of all the counties in Ireland using this page.\n\n11. Look at the page of the different counties and create a function to create the URL of the county. Create a new column in the tibble with the URL.\n\n12. Scrap the information box of each of the county to retrieve some information (established, area, elevation, population, postcode, ...).\n\n13. Perform some cleaning and export the data as csv.\n\n\n<br><br>\n\n::: {style=\"font-size: 0.875em;\"}\nBack to [week 03](/weeks/week-3.qmd) ‚èé\n:::",
    "supporting": [
      "lab-week-3_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}