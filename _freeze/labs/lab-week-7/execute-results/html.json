{
  "hash": "9c949957272da4d39e7b004959dac271",
  "result": {
    "markdown": "---\ntitle: \"Memory Issues - Tutorial\"\nengine: knitr\n---\n\n\n<br>\nThe aim of today's tutorial is to create and manipulate a large of dataset about US flights between 1987 and 2008 that represents millions on flights. You can find the data [here](https://www.kaggle.com/datasets/wenxingdi/data-expo-2009-airline-on-time-data). Note that the dataset is quite big ($\\sim 11.5$ Gb). Tue tutorial is adapted from from Alex Gold [article](https://rviews.rstudio.com/2019/07/17/3-big-data-strategies-for-r/).\n\n## Part 1 - Creating the database\n\nHere, I will assume that you have downloaded the data into a folder named `archive` and that we are in this folder. So, in that folder, you have one CSV per year between 1987 and 2008 and smaller CSV files that contain metadata of airports and planes.\n\n1. We are going to merge all the files together using bash scripting. It will results in a large file with almost $120$ millions of rows.\n\nThe first two lines will count the number of files and the number of lines of each files. We will use that to compare with the number of lines after the concatenation. We then loop over all the files (except `1987.csv`), remove the first line (`tail` command), because we do not need header for each of the file  and append the file to the `1987.csv` file (`cat` command). The `mv` command is used to rename a file. And finally, we count the number of lines in the big data file.\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nnbfiles=\"$(ls {1987..2008}.csv | wc -l)\"\nnblinesbefore=\"$(find {1987..2008}.csv -type f -exec cat {} + | wc -l)\"\n\nfor res in {1988..2008}; do\n    tail -n +2 ${res}.csv | sponge ${res}.csv\n    cat ${res}.csv >> 1987.csv\ndone;\n\nmv 1987.csv airline.csv\nnblinesafter=\"$(find airline.csv -type f -exec cat {} + | wc -l)\"\n\n```\n:::\n\n\n2. Ensure that we have not lost any lines.\n\nWe use the `$` sign to access to variable values. The `echo` command is used to print something in the terminal and the `bc` command to do the calculations.\n\n\n::: {.cell}\n\n```{.bash .cell-code}\necho \"$nblinesbefore - $nbfiles + 1\" | bc\necho $nblinesafter\n```\n:::\n\n\nThis should return the same number, which is $118 914 459$.\n\n3. Create the SQLite database.\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nsqlite3 -csv airline.sqlite3 '.import airline.csv airline'\n```\n:::\n\n\n4. Remove the unnecessary files.\n\nThe `rm` command is used to remove files. The `*` is a placeholder that can replace every character and any number of them. So, the following lines will remove all the files that start with `19` or `20` and finish with `.csv`.\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nrm 19*.csv\nrm 20*.csv\n```\n:::\n\n\n\n## Part 2 - Some statistics with bash\n\n5. Count the number of lines.\n\n6. Show the first five flights from Des Moines (DSM) to Chicago O'Hare (ORD).\n\n7. Count the number of flights for each flight number in 1993 and save it to a new file.\n\n\n## Part 3 - Analysing the data within R\n\n9. Load the library and connect to the database.\n\n10. Create a \"lazy\" tibble.\n\n11. Count the number of rows.\n\n12. Get the name of the columns.\n\n13. Created a new column `delayed` that is `TRUE` if the flight has been delayed and `FALSE` otherwise. Show the SQL query.\n\n14. Get all the flights from JFK to SFO. Bring the data to R. \n\n15. When is the best hour of the day to fly to minimise delays? What if we want to do it by year?\n\n16. Create a plot with the results.\n\n<br><br>\n\n::: {style=\"font-size: 0.875em;\"}\nBack to [week 07](/weeks/week-7.qmd) ‚èé\n:::",
    "supporting": [
      "lab-week-7_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}